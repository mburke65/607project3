---
title: "project3"
author: "group1"
date: "March 16, 2018"
output:
  html_document:
    theme: cerulean
    hightlight: tango
    css: styles.css
---

```{r setup, include=FALSE}
library(plyr)
library(tidyverse)
library(splitstackshape)
library(magrittr)
library(knitr)
```

## Our Project {.tabset}

```{r, warning=FALSE, message=FALSE}
raw.data <- read_csv('https://raw.githubusercontent.com/brian-cuny/607project3/master/multipleChoiceResponses.csv', na=c('', 'NA')) %>%
  subset(DataScienceIdentitySelect == 'Yes' & CodeWriter == 'Yes') %>%
  rowid_to_column('id')
```

### Profile of a Data Scientist: Justin



### Learning Platform Usefulness: Hovig



### Learning Categories: Brian

This subset of data examines how data scientists learned their core skill set. Each data scientist was asked to assign each category a percent from 0 to 100 indicating how much of their education was made up of this source.

First, a list of categories was extrated and formatted.

```{r}
tidy.names <- names(raw.data)[61:66] %>% 
  str_extract('(?<=LearningCategory)(\\w+)') %>% 
  str_replace_all('(?<=[a-z])([A-Z])', '_\\1') %>% 
  tolower()
tidy.names %>% kable()
```

The data was tidied and the categories were converted to factors, to aid in analysis.

```{r}
tidy.data <- raw.data %>%
  select(c(1, 61:66)) %>%
  setNames(c('id', tidy.names)) %>%
  gather('category', 'percent', 2:7, na.rm=TRUE)

tidy.data$percent %<>% as.numeric()

tidy.data$category %<>% factor(levels=tidy.names, ordered=TRUE)
tidy.data %>% head(10) %>% kable()
```

Summary statistics tell an intersting story. No source averaged more than 50% of the sets learning sources. This would seem to indicate that data scientists learn from a diverse set of sources. The 'other' category's mean is nearly 0 also indicating that the other categories account for nearly all learning sources. 

```{r}
tidy.summary.data <- tidy.data %>% 
  group_by(category) %>% 
  summarise(avg=mean(percent), sd=sd(percent))
tidy.summary.data %>% kable()
```

The boxplots support the summary statistics. Each category has numerous upper ourliers indicating that data scientists who learned most or entirely from one source were rare.

```{r}
ggplot(tidy.data) +
  geom_boxplot(aes(category, percent)) +
  xlim(tidy.names %>% rev()) +
  coord_flip() + 
  labs(x='Learning Source', 
       y='Proportion',
       title='Data Scientists Learn From Diverse Sources'
  )
```

The final more clearly shows the diversity in learning styles. This indicates that not only do data scientists learn from a variety of sources, but every data scientist's sources vary in importance. This highlights the idea that there is not right or wrong way to learn to become a data scientist. At the same time, as the four major categories amount for nearly 100% of education, this means that there are no "secret" learning sources.

```{r}
ggplot(tidy.data) +
  geom_bar(aes(category, fill=percent %>% 
                                round_any(10) %>% 
                                factor(seq(0, 100, 10))
              ), position=position_fill(reverse=TRUE)
          ) +
  scale_color_brewer(palette='Set1') + 
  theme(axis.text.x=element_text(angle=45, hjust=1)) +
  labs(x='Learning Source', 
       y='Proportion',
       title='Data Scientists Learn From Diverse Sources',
       fill='Percent'
  )
```

### Common Job Algorithms: Rose

This subset of data examines common algorithms and methods used by data scientists.

First, the proper data is subset.

```{r}
data.rose <- raw.data %>%
  select(c(1, 80:81, 134:167))

tidy.names <- c(names(data.rose)[1:4], 
                names(data.rose)[5:37] %>% 
                  str_extract('(?<=WorkMethodsFrequency)(.+)')
                )

melt.dt <- data.rose %>%
  setNames(tidy.names) %>%
  gather('WorkMethodsFrequency', 'Frequency', 5:37)
melt.dt %>% head(10) %>% kable()
```

The data on commonly used algorithms was seperated into it's own table.

```{r}
alg.select <- melt.dt %>%
  select(c('id', 'WorkAlgorithmsSelect'))
alg.select.list <- alg.select$WorkAlgorithmsSelect %>%
  strsplit(split = ",")
alg.select.dt <- tibble(id = rep(alg.select$id, sapply(alg.select.list, length)), 
                            algorithm = unlist(alg.select.list))
alg.select.dt %>% head(10) %>% kable()
```

The data on commonly used method was seperated into it's own table.

```{r}
method.select <- melt.dt %>%
  select(c('id', 'WorkMethodsSelect'))
method.select.list <- method.select$WorkMethodsSelect %>%
  as.character() %>% 
  strsplit(split = ",")
method.select.dt <- tibble(id = rep(method.select$id, sapply(method.select.list, length)), 
                               method = unlist(method.select.list))
method.select.dt %>% head(10) %>% kable()
```

Finally, the data on fequency of each method was seperated into it's own table.

```{r}
freq.dt <- melt.dt %>%
  select(c('id', 'WorkDatasetSize', 'WorkMethodsFrequency', 'Frequency'))
freq.dt %>% head(10) %>% kable()
```

ANALYSIS

### Work Tools Freqeuncy: Meaghan

The data was very untidy and expanded into two columns passed the "WorkToolsSelect" column. I brought in the 3 columns and replaced elements to ensure a easy split 

```{r message=FALSE, warning=FALSE}
tidy.names <- names(raw.data)[83:132]%>% 
  str_extract('(?<=WorkToolsFrequency)(\\w+)') %>% 
  str_replace_all('(?<=[a-z])([A-Z])', '_\\1') 

tools.data <- raw.data %>%
  select(c(1, 82:84)) %>%
  setNames(c('id', 'tool_used', "temp_1", "temp_2"))%>%
  unite_("tool_used", c("tool_used","temp_1","temp_2"))%>%
  mutate(tool_used = (str_replace_all(tool_used, '/', ',')),
         tool_used = (str_replace_all(tool_used, '_', ',')))%>%
  mutate(tool_counter =1)
tools.data <- cSplit(tools.data, 'tool_used', ',')
```

I used the gather function to reformat the table

```{r message=FALSE, warning=FALSE}
id.tool.df <- tools.data %>%
  gather(tool_group, tool, names(tools.data)[3:63])%>%
  group_by(id, tool)%>%
  summarise(sum_tool = sum(tool_counter))%>%
  drop_na()%>%
  filter(!tool %in% c("Rarely", "Often",
                      "Sometimes", "Most of the time"))
id.tool.df %>% head(10) %>% kable()
```

I created a summary table representing the frequency of each response.

```{r message=FALSE, warning=FALSE}
summary.tool.df <- tools.data %>%
  gather(tool_group, tool, names(tools.data)[3:63])%>%
  group_by(tool)%>%
  summarise(sum_tool = sum(tool_counter))%>%
  drop_na()%>%
  arrange(desc(sum_tool))%>%
  filter(!tool %in% c("Rarely", "Often",
                      "Sometimes", "Most of the time"))%>%
  mutate(percent_total = round((sum_tool/ sum(sum_tool))*100,digits = 2))
summary.tool.df %>% head(10) %>% kable()
```

This plot shows the top data science skills given the filters used.

```{r }
ggplot(head(summary.tool.df,15), aes(x=reorder(tool, -sum_tool), y=percent_total)) + 
  geom_bar(stat="identity", width=.5, fill="tomato3") +
  geom_text(aes(label=percent_total))+
  labs(x='Tool', 
       y='Percent Total',
       title="Top 15 Data Science Tools", 
       caption="Source: Multiple Choice Responses") + 
  theme(axis.text.x = element_text(angle=65, vjust=0.6))
```

A data frame of tool frequency by id was created.

```{r}
frequency.data <- raw.data %>%
  select(c(1, 83:132)) %>%
  setNames(c('id', tidy.names))

id.frquency.table <-frequency.data %>% 
  gather(tool_name, frequency_id, names(frequency.data)[2:51])%>%
  filter(frequency_id %in% c("Rarely", "Often",
                             "Sometimes", "Most of the time"))%>%
  arrange(id)
id.frquency.table %>% head(10) %>% kable()
```

I grouped the frequency information by the actual tool name & response 

```{r}
summary.frquency.table <- frequency.data %>% 
  gather(tool_name, frequency_id, names(frequency.data)[2:51])%>%
  filter(frequency_id %in% c("Rarely", "Often",
                             "Sometimes", "Most of the time"))%>%
  mutate(freq_counter =1) %>%
  group_by(tool_name,frequency_id)%>%
  summarise(sum_feq = sum(freq_counter))%>%
  arrange(desc(sum_feq))
summary.frquency.table %>% head(10) %>% kable()
```

The plot shows frequency of use of top technologies.

```{r}
ordering <- c('Most of the time', 'Often', 'Sometimes', 'Rarely')

ggplot(head(summary.frquency.table,50), aes(x = frequency_id, y = sum_feq, fill = tool_name)) + 
  geom_bar(stat = "identity") + 
  facet_wrap(~tool_name) + 
  ylab("Number of times a response was selected") + 
  xlim(ordering) +
  theme(legend.position="none") +
  theme(axis.text.x = element_text(angle = 90, 
                                   vjust = 0.5, 
                                   hjust = 1))
```



### Work Challenges: Albert


### Conclusion (writing to csv/importing to sql?)

























